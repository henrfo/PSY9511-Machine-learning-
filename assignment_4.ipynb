{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's assignment you will fit and evaluate multiple classification models based on the Heart.csv dataset from ISL, predicting whether the subjects have a heart disease (AHD). There are two main learning goals:\n",
    "- Gain more practical experience with writing analysis code, this time focusing specifically on reusing code through loops and functions.\n",
    "- Compare approaches for model performance evaluation.\n",
    "The tasks are organized such that you should be able to reuse code from the early tasks in the later ones.\n",
    "\n",
    "Note: In the text below I ask you to write some functions to do specific things. It is not a hard requirement to write exactly these functions. For instance, if you already know of an existing function performing one (or multiple) of the steps described below, feel free to use it. The goal with being so explicit is that you should focus on separation-of-concerns in your code (as discussed in Lecture 3), writing separate chunks of code with separate responsibilities and chaining them together when this is useful. With this in mind, you are free to do as you want as long as you achieve the overall goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kommentar\n",
    "- Jeg brukte totalt to, tre timer med noen problemer som jeg ikke helt skjønner fremdeles. Jeg brukte samme env som tidligere oppgaver, men flere av imports kjørte uendelig. Løste det ved å slette og lage nytt env på femte forsøk. Så måtte rase litt raskere gjennom oppgavene enn jeg foretrekker, pluss brukte Claude Code, særlig på oppgave 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare the dataset for the subsequent modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the heart disease dataset from https://www.statlearning.com/s/Heart.csv\n",
    "   -  Load the dataset and drop all variables except the predictors Age, Sex, ChestPain, RestBP, Chol, and the target variable AHD.\n",
    "   - Drop all rows containing a NaN value.\n",
    "-  Onehot encode the variable ChestPain. This means that where you before had a single column with one of four values ['typical', 'asymptomatic', 'nonanginal', 'nontypical'], you will now have four binary columns (their names don't matter), akin to 'ChestPain_typical' 'ChestPain_asymptomatic', 'ChestPain_nonanginal', 'ChestPain_nontypical'. A row that before had ChestPain='typical' will now have ChestPain_typical=1 and the other three columns set to 0, ChestPain='asymptomatic' will have ChestPain_asymptomatic=1 and the other three set to 0, etc.\n",
    "- Binary encode the target variable AHD such that 'No'=0 and 'Yes'=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('heart.csv', index_col=0)\n",
    "\n",
    "# Drop all variables except the predictors Age, Sex, ChestPain, RestBP, Chol, and the target variable AHD\n",
    "df = df[['Age', 'Sex', 'ChestPain', 'RestBP', 'Chol', 'AHD']]\n",
    "\n",
    "# Drop all rows containing a NaN value\n",
    "df = df.dropna()\n",
    "\n",
    "# Onehot encode the variable ChestPain (convert to binary 1/0)\n",
    "df = pd.get_dummies(df, columns=['ChestPain'], drop_first=False, dtype=int)\n",
    "\n",
    "# Binary encode AHD (No=0, Yes=1)\n",
    "df['AHD'] = df['AHD'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (303, 9)\n",
      "\n",
      "AHD value counts:\n",
      "AHD\n",
      "0    164\n",
      "1    139\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>AHD</th>\n",
       "      <th>ChestPain_asymptomatic</th>\n",
       "      <th>ChestPain_nonanginal</th>\n",
       "      <th>ChestPain_nontypical</th>\n",
       "      <th>ChestPain_typical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  RestBP  Chol  AHD  ChestPain_asymptomatic  ChestPain_nonanginal  \\\n",
       "1   63    1     145   233    0                       0                     0   \n",
       "2   67    1     160   286    1                       1                     0   \n",
       "3   67    1     120   229    1                       1                     0   \n",
       "4   37    1     130   250    0                       0                     1   \n",
       "5   41    0     130   204    0                       0                     0   \n",
       "\n",
       "   ChestPain_nontypical  ChestPain_typical  \n",
       "1                     0                  1  \n",
       "2                     0                  0  \n",
       "3                     0                  0  \n",
       "4                     0                  0  \n",
       "5                     1                  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the prepared dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nAHD value counts:\\n{df['AHD'].value_counts()}\")\n",
    "print(f\"\\nFirst rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit a model using a standard train/validation split through multiple steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the steps you will practice chaining functions, and you will also create the infrastructure necessary for the remaining tasks.\n",
    "\n",
    "    Write a function \"stratified_split\" that takes three arguments: A dataframe, a number of folds, and a list of variables to stratify by. The function should return a list of dataframes, one for each fold, where the dataframes are stratified by the variables in the list. Test that the function works by splitting the dataset into two folds based on 'AHD', 'Age' and 'RestBP' and print the size of each fold, the counts of 0s and 1s in AHD, and the mean of each of 'Age' and 'RestBP' (all these should be printed individually per fold). Ensure that the function does not modify the original dataframe.\n",
    "\n",
    "    Write a function 'fit_and_predict' that takes 4 arguments: A training set, a validation set, a list of predictors, and a target variable. The function should fit a logistic regression model to the training set using the predictors and target variable, and return the predictions of the model on the validation set.\n",
    "\n",
    "    Write a function 'fit_and_predict_standardized' that takes 5 arguments: A training set, a validation set, a list of predictors, a target variable, and a list of variables to standardize. Using a loop (or a scaler), the function should z-score standardize the given variables in both the training set and the validation set based on the mean and standard deviation in the training set. Then, the function should call the 'fit_and_predict' function and return its result. Ensure that the function does not modify the original dataframes. Test the function using the train and validation set from above (e.g. the two folds from the split), while standardizing the 'Age', 'RestBP' and 'Chol' variables (as mentioned above, the target should be AHD, and you should also include the remaining predictors: 'Sex' and the ChestPain-variables)\n",
    "\n",
    "    Write a function 'fit_and_compute_auc' that takes 5 arguments: A training set, a validation set, a list of predictors, a target variable, and a list of variables to standardize. The function should call the 'fit_and_predict_standardized' function to retrieve out-of-sample predictions for the validation set. Based on these and the ground truth labels in the validation set, it should compute and return the AUC. Test the function using the train and test set from above, while standardizing the 'Age', 'RestBP' and 'Chol' variables (and including the remaining predictors). Print the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a 'function stratified_split'\n",
    "\n",
    "def stratified_split(df, n_folds, stratify_vars):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Stratify only on the first variable\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    folds = []\n",
    "    \n",
    "    for _, fold_idx in skf.split(df_copy, df_copy[stratify_vars[0]]):\n",
    "        folds.append(df_copy.iloc[fold_idx])\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a 'function fit_and_predict'\n",
    "\n",
    "def fit_and_predict(train, validation, predictors, target):\n",
    "    # Fit logistic regression on training set\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(train[predictors], train[target])\n",
    "    \n",
    "    # Return predictions on validation set\n",
    "    predictions = model.predict_proba(validation[predictors])[:, 1]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function 'fit_and_predict_standardized'\n",
    "\n",
    "def fit_and_predict_standardized(train, validation, predictors, target, standardize_vars):\n",
    "    train_copy = train.copy()\n",
    "    validation_copy = validation.copy()\n",
    "    \n",
    "    # Standardize based on training set statistics\n",
    "    for var in standardize_vars:\n",
    "        mean = train_copy[var].mean()\n",
    "        std = train_copy[var].std()\n",
    "        train_copy[var] = (train_copy[var] - mean) / std\n",
    "        validation_copy[var] = (validation_copy[var] - mean) / std\n",
    "    \n",
    "    return fit_and_predict(train_copy, validation_copy, predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a 'function fit_and_compute_auc'\n",
    "\n",
    "def fit_and_compute_auc(train, validation, predictors, target, standardize_vars):\n",
    "    # Get predictions from fit_and_predict_standardized\n",
    "    predictions = fit_and_predict_standardized(train, validation, predictors, target, standardize_vars)\n",
    "    \n",
    "    # Compute and return AUC\n",
    "    auc = roc_auc_score(validation[target], predictions)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Size: 152\n",
      "  AHD=0: 82\n",
      "  AHD=1: 70\n",
      "  Mean Age: 55.41\n",
      "  Mean RestBP: 131.55\n",
      "\n",
      "Fold 1:\n",
      "  Size: 151\n",
      "  AHD=0: 82\n",
      "  AHD=1: 69\n",
      "  Mean Age: 53.46\n",
      "  Mean RestBP: 131.83\n",
      "\n",
      "First 5 predictions: [0.25366754 0.16440969 0.03742883 0.53852323 0.72382675]\n",
      "\n",
      "AUC: 0.8501\n"
     ]
    }
   ],
   "source": [
    "# Test stratified_split: split into 2 folds and print stats for each fold\n",
    "folds = stratified_split(df, 2, ['AHD', 'Age', 'RestBP'])\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Size: {len(fold)}\")\n",
    "    print(f\"  AHD=0: {(fold['AHD'] == 0).sum()}\")\n",
    "    print(f\"  AHD=1: {(fold['AHD'] == 1).sum()}\")\n",
    "    print(f\"  Mean Age: {fold['Age'].mean():.2f}\")\n",
    "    print(f\"  Mean RestBP: {fold['RestBP'].mean():.2f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Test fit_and_predict_standardized: get predictions on validation set\n",
    "train = folds[0]\n",
    "validation = folds[1]\n",
    "predictors = ['Age', 'Sex', 'RestBP', 'Chol', 'ChestPain_asymptomatic', \n",
    "              'ChestPain_nonanginal', 'ChestPain_nontypical', 'ChestPain_typical']\n",
    "target = 'AHD'\n",
    "standardize_vars = ['Age', 'RestBP', 'Chol']\n",
    "\n",
    "predictions = fit_and_predict_standardized(train, validation, predictors, target, standardize_vars)\n",
    "print(f\"First 5 predictions: {predictions[:5]}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Test fit_and_compute_auc: compute and print AUC\n",
    "auc = fit_and_compute_auc(train, validation, predictors, target, standardize_vars)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform a cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the 'stratified_split' function to split the dataset into 10 folds, stratified on variables you find reasonable. For each fold, use the 'fit_and_compute_auc' function to compute the AUC of the model on the held-out validation set. Print the mean and standard deviation of the AUCs across the 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: AUC = 0.7941\n",
      "Fold 1: AUC = 0.8613\n",
      "Fold 2: AUC = 0.7815\n",
      "Fold 3: AUC = 0.8824\n",
      "Fold 4: AUC = 0.8125\n",
      "Fold 5: AUC = 0.8348\n",
      "Fold 6: AUC = 0.9509\n",
      "Fold 7: AUC = 0.8616\n",
      "Fold 8: AUC = 0.9107\n",
      "Fold 9: AUC = 0.7723\n",
      "\n",
      "Mean AUC: 0.8462\n",
      "Std AUC: 0.0552\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "ten_folds = stratified_split(df, 10, ['AHD', 'Sex'])\n",
    "\n",
    "# Define predictors and target\n",
    "predictors = ['Age', 'Sex', 'RestBP', 'Chol', 'ChestPain_asymptomatic', \n",
    "              'ChestPain_nonanginal', 'ChestPain_nontypical', 'ChestPain_typical']\n",
    "target = 'AHD'\n",
    "standardize_vars = ['Age', 'RestBP', 'Chol']\n",
    "\n",
    "# Compute AUC for each fold\n",
    "aucs = []\n",
    "for i in range(len(ten_folds)):\n",
    "    # Use fold i as validation, combine others as training\n",
    "    validation = ten_folds[i]\n",
    "    train = pd.concat([ten_folds[j] for j in range(len(ten_folds)) if j != i])\n",
    "    \n",
    "    # Compute AUC\n",
    "    auc = fit_and_compute_auc(train, validation, predictors, target, standardize_vars)\n",
    "    aucs.append(auc)\n",
    "    print(f\"Fold {i}: AUC = {auc:.4f}\")\n",
    "\n",
    "# Print mean and standard deviation\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Std AUC: {np.std(aucs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. OPTIONAL: Use the bootstrap to achieve a distribution of out-of-bag AUCs.\n",
    "\n",
    "For 100 iterations, create a bootstrap sample by sampling with replacement from the full dataset until you have a training set equal in size to 80% of the original data. Use the observations not included in the bootstrap sample as the validation set for that iteration.. Fit models and calculate AUCs for each iteration. Print the mean and standard deviation of the AUCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rakk dessverre ikke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Theory\n",
    "\n",
    "List some benefits of wrapping code in functions rather than copying and pasting it multiple times.\n",
    "- Saves time, efficient, reproducible workflow, more overview of function and fewer possibilities for errors.\n",
    "\n",
    "Explain three classification metrics and their benefits and drawbacks.\n",
    "- Recall: correctly classified actual positives / all actual positives\n",
    "Benefit: Critical when missing positives is costly (e.g. disease detection - can't miss sick patients).\n",
    "Drawback: ignores false positives, meaning you could predict everything as positive and get 100%, but it's not truly useful.\n",
    "\n",
    "- Accuracy = correct classifications / total classifications\n",
    "Benefit: Simple, intuitive, and shows overall model performance.\n",
    "Drawback: can be misleading with imbalanced classes, meaning if e.g 90% of a class is 0, then always classifying as 0 would give 90% accuracy.\n",
    "\n",
    "- Precision: correctly classified actual positives / everything classified as positive\n",
    "Benefit: Important when false positives are costly (e.g. spam filtering - don't want real emails blocked)\n",
    "Drawback: ignores false negatives, meaning you could predict very few positives and get high precision, while missing most of the actual positive values.\n",
    "\n",
    "Write a couple of sentences comparing the three methods (train/validation, cross-validation, bootstrap) above as approaches to quantify model performance. Which one yielded the best results?\n",
    "The Mean AUC of cross-val was .85, and the AUC of train/val: .85, however, for the train/val we have one split that could be slightly imbalanced or not, and for the cross-val AUC, we have ten different splits, and the mean of that. So its difficult so state whether one is better than the other. Cross-val is more reliable, train/val is more variable.\n",
    "     \n",
    "Which one would you expect to yield the best results?\n",
    "- Train/val depends on split, while cross-val is a mean of e.g. 10 folds, possibly providing a more realistic AUC score. If we ran bootstrap, it would possibly be on the more positive side of yielding \"best results\"\n",
    "\n",
    "Can you mention some theoretical benefits and drawbacks with each? Even if you didn't do the optional bootstrap exercise you should reflect on this as an approach.\n",
    "- Train/val: fast and simple, and can be a cleaner split, but also dependent on balance between splits\n",
    "- Cross-val: also helpful for smaller datasets, and provides more reliable estimates, given many smaller folds, but can be computationally expensive given k models and n folds\n",
    "- Bootstrap: sometimes positive-biased, but provides confidence intervals and helpful for smaller datasets because the same data can appear in both train and test datasplits\n",
    "\n",
    "Why do we stratify the dataset before splitting?\n",
    "- to balance our data, and not get skewed splits\n",
    "\n",
    "What other use cases can you think of for the bootstrap method?\n",
    "- confidence intervals and small datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PSY9511_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
